{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec11f7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809cdb40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c1767a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Not all problems are continuous\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a6269d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- There are instances where we want to determine a binary state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c29c9b2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Logistic regression is good for qualitative results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43d302",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Logistic regression is concerned with the probability that a response falls into a particular category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dd7f97",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Evaluating Classification\n",
    "\n",
    "- True Positives\n",
    "- True Negatives\n",
    "- False Positives\n",
    "- False Negatives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee4c74d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Logistic regression uses a Sigmoid function for situations where outputs can have one of two values either 0 or 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bb1a18",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\omega(z)=\\frac{1}{1+e^{-z}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24357eb6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "\n",
    "x = np.linspace(-6,6,100)\n",
    "plt.plot(x,sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336928f8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Take our linear regression solution and put it into a logistic model**\n",
    "\n",
    "$$\\omega(z)=\\frac{1}{1+e^{-(x\\beta + \\epsilon)}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea232a9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Example: Sinking of the Titanic\n",
    "\n",
    "The Challenge:\n",
    "\n",
    "The sinking of the Titanic is one of the most infamous shipwrecks in history.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dd8951",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed792de",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0bba22",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this challenge, we ask you to build a predictive model that answers the question: “what sorts of people were more likely to survive?” using passenger data (ie name, age, gender, socio-economic class, etc).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ebd9d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use pandas to read in csv file\n",
    "train = pd.read_csv('./data/titanic/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934b8a2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65293291",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Locates and Visualizes the Missing Values\n",
    "\n",
    "- You cannot train a machine learning model with missing values. It will not know what to do.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af2e685",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use the .isnull() method to locate missing data\n",
    "missing_values = train.isnull()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03736e3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use seaborn to conduct heatmap to identify missing data\n",
    "# data -> argument refers to the data to create heatmap\n",
    "# yticklabels -> argument avoids plotting the column names\n",
    "# cbar -> argument identifies if a colorbar is required or not\n",
    "# cmap -> argument identifies the color of the heatmap\n",
    "sns.heatmap(data = missing_values, yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3902f8ff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Step 1: Viewing the ratios of the labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab85d620",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use the countplot() method to identify ratio of who survived vs. not\n",
    "# (Tip) very helpful to get a visualization of the target label\n",
    "# x -> argument refers to column of interest\n",
    "# data -> argument refers to dataset\n",
    "sns.countplot(x='Survived', data=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6425db",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Survival Based on Category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d4f830",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use the countplot() method to identify ratio of who survived vs. not with interest in Passenger class\n",
    "# x -> argument refers to column of interest\n",
    "# data -> argument refers to dataset\n",
    "# hue -> allows another level to subdivide data\n",
    "# palette -> argument refers to plot color\n",
    "sns.countplot(x='Survived', data=train, hue='Pclass')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6194031f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**What to do with all this missing data?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15183d20",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can impute or infill these values based on the data distribution\n",
    "\n",
    "- When doing this it is important to look at the data distribution to make sure this makes sense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d47ab76",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.violinplot(x='Pclass', y='Age', data = train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bb84a9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 2: Create a function to Impute Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f5921f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create function to impute the age value if it is null\n",
    "def impute_age(cols):\n",
    "    Age = cols[0]\n",
    "    Pclass = cols[1]\n",
    "    \n",
    "    if pd.isnull(Age):\n",
    "        \n",
    "        if Pclass == 1:\n",
    "            return 37\n",
    "        elif Pclass == 2:\n",
    "            return 29\n",
    "        else:\n",
    "            return 24\n",
    "    else:\n",
    "        return Age\n",
    "    \n",
    "    \n",
    "# Apply function to impute the age for missing values\n",
    "# The age column is at position 0\n",
    "# The pclass column is at position 1\n",
    "# axis -> argument refers to columns instead of rows to apply the impute_age function\n",
    "train['Age'] = train[['Age', 'Pclass']].apply(impute_age, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45978e8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create function to replace the few empty Embark Values\n",
    "def impute_embark(cols, value):\n",
    "    embark = cols[0]\n",
    "    \n",
    "    if pd.isnull(embark):\n",
    "        return value\n",
    "    else: \n",
    "        return embark\n",
    "\n",
    "    \n",
    "train['Embarked'] = train[['Embarked']].apply(impute_embark, axis=1, args = (train['Embarked'].mode()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318c9257",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 3: Visualize Imputed Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c03de",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**It is always important when you modify data you check that it worked**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33703fcb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(train.isnull(), yticklabels=False, cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2bb17e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**There are barely any cabin entries we should ignore them**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689349a1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# use .dropna() method to remove rows that contain missing values\n",
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f06041a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 4: Encoding Categorical Variables\n",
    "\n",
    "**What should we do with categorical variables?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f518f2e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We need to convert categorical variables (not understood by computers) into dummy variables that can be understood.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9da2035",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Produces what is known as a one-hot encoded vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb77a9a1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![](./figs/one_hot_encoded.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c040ce9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use the .get_dummies() method to convert categorical data into dummy values\n",
    "# train['Sex'] refers to the column we want to convert\n",
    "# drop_first -> argument avoids the multicollinearity problem, which can undermines\n",
    "# the statistical significance of an independent variable.\n",
    "sex = pd.get_dummies(train['Sex'], drop_first=True) # drop first means k-1 values\n",
    "embark = pd.get_dummies(train['Embarked'], drop_first=True)\n",
    "\n",
    "# Use  .concat() method to merge the series data into one dataframe\n",
    "train = pd.concat([train, sex, embark], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d509916",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 5: Data Filtering\n",
    "\n",
    "Remove any insignificant features from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d2177",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Drop columns with categorical data\n",
    "train.drop(['Sex','Embarked','Ticket','Name','PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92baf66a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Step 6: Split the data into features and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943a00d7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Split data into 'X' features and 'y' target label sets\n",
    "X = train[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'male', 'Q',\n",
    "       'S']]\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84880e5f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 7: Test/Train Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c232d77b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Split data set into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99f57fd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 8: Create and Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04cd9e27",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create instance (i.e. object) of LogisticRegression\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m logmodel \u001b[38;5;241m=\u001b[39m \u001b[43mLogisticRegression\u001b[49m()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Fit the model using the training data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# X_train -> parameter supplies the data features\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# y_train -> parameter supplies the target labels\u001b[39;00m\n\u001b[0;32m      7\u001b[0m logmodel\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "# Create instance (i.e. object) of LogisticRegression\n",
    "logmodel = LogisticRegression()\n",
    "\n",
    "# Fit the model using the training data\n",
    "# X_train -> parameter supplies the data features\n",
    "# y_train -> parameter supplies the target labels\n",
    "logmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625371e0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predictions = logmodel.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502ee3ac",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Step 9: Score the Model\n",
    "\n",
    "#### F1-Score\n",
    "\n",
    "It is calculated from the precision and recall of the test\n",
    "\n",
    "- **Precision** is the number of true positive results divided by the number of all positive results, including those not identified correctly\n",
    "  - known as positive predictive value\n",
    "\n",
    "$$ Precision = \\frac{True\\,Positives}{True\\,Positives + False\\,Positives} $$\n",
    "\n",
    "    - within everything that is predicted positive this is the percentage correct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b735795",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Recall** is the number of true positive results divided by the number of all samples that should have been identified as positive.\n",
    "  - known as sensitivity in diagnostic binary classification\n",
    "\n",
    "$$ Recall = \\frac{True\\,Positives}{True\\,Positives + False\\,Negatives} $$\n",
    "\n",
    "    - what is the fraction of actual positive results the model found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8a0cc8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "F_1 = \\frac{2}{\\mathrm{recall}^{-1} + \\mathrm{precision}^{-1}} = 2 \\frac{\\mathrm{precision} \\cdot \\mathrm{recall}}{\\mathrm{precision} + \\mathrm{recall}} = \\frac{2\\mathrm{tp}}{2\\mathrm{tp} + \\mathrm{fp} + \\mathrm{fn}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4ef382",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step 10: Visualizing Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a45d24",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# computes the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ebfca6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Plots the confusion matrix\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.viridis)\n",
    "classNames = ['Negative','Positive']\n",
    "plt.title('Titanic Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "tick_marks = np.arange(len(classNames))\n",
    "plt.xticks(tick_marks, classNames, rotation=45)\n",
    "plt.yticks(tick_marks, classNames)\n",
    "s = [['TN','FP'], ['FN', 'TP']]\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76586508",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multiclass classification\n",
    "\n",
    "If you have several classes to predict, an option often used is to fit one-versus-all classifiers and then use a voting heuristic for the final decision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4875ae73",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# loads the dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Instantiates the model and computes the logistic regression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                         multi_class='multinomial').fit(X, y)\n",
    "\n",
    "# This predicts the classes\n",
    "clf.predict(X[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b53e356",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# predicting the probability\n",
    "clf.predict_proba(X[:2, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698d9de4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Shows the score for the model\n",
    "clf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6621aa45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.10.0 ('jupyterbook')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c475b5beda6d617ffb7b2fcf453fbe132321ffc1e1f96c06cf49356e1e7f42cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
