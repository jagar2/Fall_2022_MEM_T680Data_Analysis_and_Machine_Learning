# Final Exam
## December 7, 2022 8:00-10:00
## Lebow 134

The exam will consist of two parts. 
1. A written closed-book exam testing conceptual concepts.
2. A machine learning assigment which will be provide at least a week prior to the exam. This assignment will be due at the same time as the exam. 

For the open book part of the exam you can communicate with classmates but do not share code. Please track all changes on github so I can see your effort. 

Topics for Final Written Exam:
1. The 4 V's of big data
2. The concept of FAIR data
3. Questions on the basics of python programming
   - Predicting outputs of a short code
   - Explaining the utility of certain types of functions (e.g., lambda functions)
   - Interpreting an error message
   - Difference between deep and shallow copies (what is the advantage/disadvantage)
4. Understanding of the importance of color maps. Why do they make a matter? 
5. Given some data describe a visualization for information discovery from data
6. Matching an application to a common package in python
7. Understanding of how edge detectors work, how to deal with noise? Why are edge detectors important?
8. The difference between supervised and unsupervised learning
9. Understanding the concept of overfitting and how to combat overfitting with regularization methods
10. Conceptual understanding of simple machine learning models including support vector machines, k-nearest neighbors, and decision trees
11. What is the curse of dimensionality and how might you deal with it?
12. Difference between lasso L1 and ridge L2 regression. Why might you use them? What are the implications? 
13. Steps in a machine learning pipeline. If presented with data, how would you approach the problem? 
14. A conceptual understanding of PCA, how might it be valuable in machine learning pipelines
15. What is manifold learning and why might it be a valuable tool
16. Conceptual understanding of how a neural network works and the various components:
    1.  What are neurons and what is their structure
    2.  Activation functions and non-linearity
    3.  Loss functions
    4.  Optimization algorithms
    5.  Autodifferentiation